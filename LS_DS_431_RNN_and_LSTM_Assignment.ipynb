{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "U4-S3-DNN (Python 3.7)",
      "language": "python",
      "name": "u4-s3-dnn"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "LS_DS_431_RNN_and_LSTM_Assignment.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andronikmk/DS-Unit-4-Sprint-3-Deep-Learning/blob/master/LS_DS_431_RNN_and_LSTM_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0q88dzjO5LTm",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
        "\n",
        "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
        "\n",
        "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
        "\n",
        "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
        "\n",
        "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
        "\n",
        "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
        "\n",
        "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
        "\n",
        "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ltj1je1fp5rO",
        "colab": {}
      },
      "source": [
        "# TODO - Words, words, mere words, no matter from the heart."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb75G_Hj52oK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e16871c7-7c54-4d30-a3ac-3a80ac2ddb38"
      },
      "source": [
        "!pip install tensorflow==2.0.0"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/0f/7bd55361168bb32796b360ad15a25de6966c9c1beb58a8e30c01c8279862/tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (86.3MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3MB 47kB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.18.2)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 42.9MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 42.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.34.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.9.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.10.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.2.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.0.8)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.12.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.2.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.21.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.7.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (46.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0) (2.8.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.0)\n",
            "\u001b[31mERROR: tensorflow-federated 0.12.0 has requirement tensorflow~=2.1.0, but you'll have tensorflow 2.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-federated 0.12.0 has requirement tensorflow-addons~=0.7.0, but you'll have tensorflow-addons 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_core",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgeGdc6B5slr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6305a1fb-bb73-4cf8-d113-5596f13e5333"
      },
      "source": [
        "# import libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import os\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX5163pb8t6Z",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "0d3a0e97-34e4-4663-834c-c5ecd6632216"
      },
      "source": [
        "# import zipped text file\n",
        "from zipfile import ZipFile\n",
        "\n",
        "file_name = \"/content/text.zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7Yo4yAE9DJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_files = os.listdir('/content/text')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpM89KVF9HdZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read in Data\n",
        "\n",
        "data = []\n",
        "\n",
        "for file in data_files:\n",
        "    if file[-3:] == 'txt':\n",
        "        with open(f'./text/{file}', 'r', encoding='utf-8') as f:\n",
        "            data.append(f.read())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqT-ZCDO9Mvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode Data as Chars\n",
        "\n",
        "# Gather all text \n",
        "# Why? 1. See all possible characters 2. For training / splitting later\n",
        "text = \" \".join(data)\n",
        "\n",
        "# Unique Characters\n",
        "chars = list(set(text))\n",
        "\n",
        "# Lookup Tables\n",
        "char_int = {c:i for i, c in enumerate(chars)} \n",
        "int_char = {i:c for i, c in enumerate(chars)} "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izgIYUTT9u2f",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "694f89d5-dfe9-43a6-cf9c-4040ff0db1cf"
      },
      "source": [
        "len(chars)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "107"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm44Lur29uwU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "21decd3b-0acc-45b6-ae47-58f6a5abd17f"
      },
      "source": [
        "# Create the sequence data\n",
        "\n",
        "maxlen = 40\n",
        "step = 5\n",
        "\n",
        "encoded = [char_int[c] for c in text]\n",
        "\n",
        "sequences = [] # Each element is 40 chars long\n",
        "next_char = [] # One element for each sequence\n",
        "\n",
        "for i in range(0, len(encoded) - maxlen, step):\n",
        "    \n",
        "    sequences.append(encoded[i : i + maxlen])\n",
        "    next_char.append(encoded[i + maxlen])\n",
        "    \n",
        "print('sequences: ', len(sequences))"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sequences:  1114623\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOw7zUAU9utw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        },
        "outputId": "34aa2c9e-0ae3-47bb-d295-7741755abebc"
      },
      "source": [
        "sequences[0]"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[47,\n",
              " 72,\n",
              " 8,\n",
              " 46,\n",
              " 51,\n",
              " 64,\n",
              " 65,\n",
              " 13,\n",
              " 40,\n",
              " 19,\n",
              " 33,\n",
              " 35,\n",
              " 40,\n",
              " 65,\n",
              " 39,\n",
              " 74,\n",
              " 65,\n",
              " 46,\n",
              " 60,\n",
              " 11,\n",
              " 31,\n",
              " 19,\n",
              " 104,\n",
              " 66,\n",
              " 65,\n",
              " 19,\n",
              " 16,\n",
              " 51,\n",
              " 58,\n",
              " 43,\n",
              " 41,\n",
              " 65,\n",
              " 40,\n",
              " 65,\n",
              " 19,\n",
              " 102,\n",
              " 51,\n",
              " 46,\n",
              " 49,\n",
              " 31]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhnFS0Gw922M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create x & y\n",
        "\n",
        "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sequences),len(chars)), dtype=np.bool)\n",
        "\n",
        "for i, sequence in enumerate(sequences):\n",
        "    for t, char in enumerate(sequence):\n",
        "        x[i,t,char] = 1\n",
        "        \n",
        "    y[i, next_char[i]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U-mEwD3-H3W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fa66f5be-c218-4797-9905-7d44eb507469"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1114623, 40, 107)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0Dh4EdF-MRU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "1d588d62-d6f6-4f6b-b4a1-12f26e79b7a1"
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1114623, 107)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ra7kkmbC-N6l",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "outputId": "cfb6fb62-cc6b-4e2f-a0b2-936afd4f21ca"
      },
      "source": [
        "# build the model: a single LSTM\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars)), dropout=.2))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 128)               120832    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 107)               13803     \n",
            "=================================================================\n",
            "Total params: 134,635\n",
            "Trainable params: 134,635\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz4ebaUo-P5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds):\n",
        "    # helper function to sample an index from a probability array\n",
        "    # Takes predictions and translates them into a character.\n",
        "    # Into a position of a chracter.\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / 1\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2vLpI8R-TXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    \n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "    \n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    \n",
        "    generated = ''\n",
        "    \n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    \n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "    \n",
        "    for i in range(400):\n",
        "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_int[char]] = 1\n",
        "            \n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds)\n",
        "        next_char = int_char[next_index]\n",
        "        \n",
        "        sentence = sentence[1:] + next_char\n",
        "        \n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    print()\n",
        "\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCVCDeu9-WAX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "ee26252f-8a90-4f26-fc4b-da50e5f972e8"
      },
      "source": [
        "# fit the model\n",
        "\n",
        "model.fit(x, y,\n",
        "          batch_size=1024,\n",
        "          epochs=10,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1114623 samples\n",
            "Epoch 1/10\n",
            "1114112/1114623 [============================>.] - ETA: 0s - loss: 2.7499\n",
            "----- Generating text after Epoch: 0\n",
            "----- Generating with seed: \"but two shirts\n",
            "  out with me, and I mean\"\n",
            "but two shirts\n",
            "  out with me, and I mean,\n",
            "      s loand moly thy ae calltht foel\n",
            " hethders ap; fapenpe noty; oo hor! UNATPLERU. Hlor Ice. mithe louahf'n.\n",
            "s  Ms nir, Aghin dorsos, yod ar Ont eiee,  yo watn ord gheis.\n",
            "Dart Phawcee fou to nou dUs not frans arertoTho; to  is iw shekoTh serings wont lo:e pfro,\n",
            "\n",
            "     Er slo kin horlas? I I  lothat yf maan; o d seit entin  I the thut\n",
            "or womesl tes, ant,  entsen hyy\n",
            "Hut t yon.\n",
            "\n",
            " CURARE. Hacgfit\n",
            "1114623/1114623 [==============================] - 1549s 1ms/sample - loss: 2.7498\n",
            "Epoch 2/10\n",
            "1114112/1114623 [============================>.] - ETA: 0s - loss: 2.3622\n",
            "----- Generating text after Epoch: 1\n",
            "----- Generating with seed: \"ich, unrevers'd, stands in effectual for\"\n",
            "ich, unrevers'd, stands in effectual for\n",
            "\n",
            "merseebll niw, of lid ghet not to thaed the this ane.\n",
            "\n",
            " ELIE.\n",
            "Ge ho shad thew ahe forser fatd ake sewes of hem; The tertme Bh thay.\n",
            "  Ar out at you wellr he hath in herods.\n",
            "   hntaly Lesch; chobll yo  pureT,\n",
            "  n surd tis thich oheu thare the guls nf less.\n",
            " hin yourpplowis’rnd.\n",
            "I geow it Ify to dea w,\n",
            "merhand he ance.\n",
            "\n",
            "FFUCPIO.. to eap ig weas med werm boecth me eed,\n",
            "    ' Epot khot bey oow, lis \n",
            "1114623/1114623 [==============================] - 1396s 1ms/sample - loss: 2.3621\n",
            "Epoch 3/10\n",
            "1114112/1114623 [============================>.] - ETA: 0s - loss: 2.2660\n",
            "----- Generating text after Epoch: 2\n",
            "----- Generating with seed: \"anquish'd doth yield\n",
            "  To those two armi\"\n",
            "anquish'd doth yield\n",
            "  To those two armienisult; apvith sover\n",
            "    Sheurfoat fuizhet on the buaetcetharlds; it lodd,\n",
            "Frver  my eruie.\n",
            "\n",
            "  AN. Thal orpcrste!\n",
            "\n",
            "ORILO.\n",
            "MABreaith beanode of pisplean.\n",
            "    He\n",
            "wile yoo tar to lunher erest dotid whye.\n",
            "But as, mintion is lep, to bece whit abe nhe.\n",
            "    ATI band lies Foldms do torwice susp,\n",
            "    sncee ond stoab;\n",
            "I nind foh mos saed on orou the len is a disware.\n",
            "  e dome oad stoten it thase asteremn o\n",
            "1114623/1114623 [==============================] - 1527s 1ms/sample - loss: 2.2660\n",
            "Epoch 4/10\n",
            "1114112/1114623 [============================>.] - ETA: 0s - loss: 2.2062\n",
            "----- Generating text after Epoch: 3\n",
            "----- Generating with seed: \" my fawn,\n",
            "    And give it food. There is\"\n",
            " my fawn,\n",
            "    And give it food. There is us ore hice eaved Hus alves.\n",
            "  ALALITFUD. Nomedo ou such st mad sut you hillubson\n",
            "And thas rowe you hate such a sondire her you, Tin thess, Iellush mast-is be.\n",
            "F Mane, aill Mo fayem’st aro'n mome, on the greald whan your and,\n",
            "   MERIUD. Madlie to me hou toort joit, Com nocen torear\n",
            "\n",
            "RUCIAL\n",
            "\n",
            "Gmy, an toontf to hy nable ird fay, All sping?\n",
            "    I  eclirt ede he wigh so so a’ll tur to thas uble\n",
            "Gow\n",
            "le\n",
            "1114623/1114623 [==============================] - 1551s 1ms/sample - loss: 2.2062\n",
            "Epoch 5/10\n",
            "1114112/1114623 [============================>.] - ETA: 0s - loss: 2.1621\n",
            "----- Generating text after Epoch: 4\n",
            "----- Generating with seed: \"That only to stand high in your account,\"\n",
            "That only to stand high in your account,\n",
            "For burgay if lor in alp of then wetLerts\n",
            "    Tidropisss of the espaty Coslebt hith.\n",
            "    If emelssidnot you, chees whithte’d Sif to that\n",
            " ATherg son stoke.\n",
            "\n",
            "RADIOUS.\n",
            "Havo, beings]\n",
            "  PUSTIRK. Troids and frrices!\n",
            "    For ere Kispecknofe siass, me nut Pacee,\n",
            "That, with wimsels a diow muse nopterust\n",
            "    Didstume tourl wall gasetllemin har cose\n",
            "\n",
            "      perEf rote of list sut no sulle\n",
            "\n",
            "hate the cunercti\n",
            "1114623/1114623 [==============================] - 1454s 1ms/sample - loss: 2.1620\n",
            "Epoch 6/10\n",
            "1114112/1114623 [============================>.] - ETA: 0s - loss: 2.1250\n",
            "----- Generating text after Epoch: 5\n",
            "----- Generating with seed: \"ccess to electronic\n",
            "works by freely shar\"\n",
            "ccess to electronic\n",
            "works by freely share proincest betire,\n",
            "An that Lith in the lomars faveless\n",
            "Bear hare hearwaice. KINGY ELOYE.—(3; leear yot the poth a beill’s lor.\n",
            "    men me ho bair! At cSoe hiv? I knace,\n",
            "Siel coon wich you Wreen this to ny winiena, I nor\n",
            "    Iuch a entere hath', gurterice.\n",
            "GoNAgDANE, Mase wo my brencebaul, it etbrnds,\n",
            "    Cad thy hortia’s hee thou s pay? That sutokel'os aun.\n",
            "And ferdean a she wiplet our wraige sor\n",
            "1114623/1114623 [==============================] - 1393s 1ms/sample - loss: 2.1250\n",
            "Epoch 7/10\n",
            "1114112/1114623 [============================>.] - ETA: 0s - loss: 2.0961\n",
            "----- Generating text after Epoch: 6\n",
            "----- Generating with seed: \",\n",
            "Due reference of place and exhibition,\"\n",
            ",\n",
            "Due reference of place and exhibition,\n",
            "silayecs wnt you sevee here -rich;\n",
            "That, parritils you has sord all of fores.\n",
            "\n",
            " YOURUST.\n",
            "How you nou medd!\n",
            "Bet that not'ded saold give saire to try live\n",
            "               2ent the and t\n",
            "  We liew is a the mentsed ue even my fors,\n",
            "You fe ritett ens buatk! nat hen will the Lokes;\n",
            "    Yod do guck portht well wise, Langedfor\n",
            "erpeard. Wher! My flyss hasing, clava\n",
            "Helly our nith midver apt teathtight;\n",
            "And\n",
            "1114623/1114623 [==============================] - 1552s 1ms/sample - loss: 2.0961\n",
            "Epoch 8/10\n",
            "1114112/1114623 [============================>.] - ETA: 0s - loss: 2.0728\n",
            "----- Generating text after Epoch: 7\n",
            "----- Generating with seed: \"eboyes) will be seene\n",
            "And quickly, yours\"\n",
            "eboyes) will be seene\n",
            "And quickly, yours I shell viusor. Weeps pieain to buppetus my eedafd.\n",
            "\n",
            "LAsCLLO.\n",
            "He wh’t’s noz, whys me som; Hy a sermcon pithie quiritel. It Beare!\n",
            "\n",
            "PALY.\n",
            "Go, lyst foubon, it mes\n",
            "    I dore they from nower the past.\n",
            "Shat at brighe fan wail hact to at nut sart\n",
            "\n",
            "   FOe Heav'stion an chercacel’d on up weet\n",
            "    Frengnst on you. Thos his faid the nreees; with morew parp!\n",
            "As ourchom he. Rade ma, me.\n",
            " HALMAN. and mast?\n",
            " \n",
            "1114623/1114623 [==============================] - 1414s 1ms/sample - loss: 2.0728\n",
            "Epoch 9/10\n",
            "1114112/1114623 [============================>.] - ETA: 0s - loss: 2.0518\n",
            "----- Generating text after Epoch: 8\n",
            "----- Generating with seed: \"rtly touching or concerning the\n",
            "discipli\"\n",
            "rtly touching or concerning the\n",
            "disciplids serdablegent;\n",
            "The rriny one siget mudwos her not out\n",
            "There aliec tank cincion youtwdysonn,\n",
            "A pracent lebss fatired shat sillder, weldey. Fords beavel,\n",
            "Ang the pirivithing cemice! whis prasest ore usstild\n",
            "tin of gie weem stase:\n",
            "    Sheifs, me for harn'd the vancelir weilty.\n",
            "  LOADES.. Hows prekety! He kneve on Mark new Seallseas?\n",
            "\n",
            "PARRIN.\n",
            "Ay, and when! Cloughtot wealk toun? Is theentare\n",
            "    you \n",
            "1114623/1114623 [==============================] - 1305s 1ms/sample - loss: 2.0518\n",
            "Epoch 10/10\n",
            "1114112/1114623 [============================>.] - ETA: 0s - loss: 2.0339\n",
            "----- Generating text after Epoch: 9\n",
            "----- Generating with seed: \"extant.\n",
            "\n",
            "EMILIA.\n",
            "The Sun grows high, let\"\n",
            "extant.\n",
            "\n",
            "EMILIA.\n",
            "The Sun grows high, let ugverrest. Cosy is to sly?\n",
            "  KING. Nay, the wornes, tell se; I aram? Phot there.\n",
            "A’ll the Dingh I wourd ut I puithes as enfeCle oo.\n",
            "Ma say. Leuglerik, acle, is thy spaccinas;\n",
            "    Whis did drok thy tolds from gook’d peafing\n",
            "    Mared in his not ourss your undlet.\n",
            "  DUALA. I Core, I lave in\n",
            "Hore uty not tarsh, and Deace Sime  ceide.\n",
            "  MOSEOFIR. If edif colloking all quele of the ener? and,\n",
            "Burblonk\n",
            "1114623/1114623 [==============================] - 1406s 1ms/sample - loss: 2.0339\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1cba91a5f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zE4a4O7Bp5x1"
      },
      "source": [
        "# Resources and Stretch Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "## Stretch goals:\n",
        "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
        "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
        "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
        "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
        "- Run on bigger, better data\n",
        "\n",
        "## Resources:\n",
        "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
        "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
        "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
        "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
        "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
      ]
    }
  ]
}
{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "U4-S3-DNN (Python 3.7)",
      "language": "python",
      "name": "u4-s3-dnn"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "LS_DS_431_RNN_and_LSTM_Assignment.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andronikmk/DS-Unit-4-Sprint-3-Deep-Learning/blob/master/module1-rnn-and-lstm/LS_DS_431_RNN_and_LSTM_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0q88dzjO5LTm",
        "colab_type": "text"
      },
      "source": [
        "<img align=\"left\" src=\"https://lever-client-logos.s3.amazonaws.com/864372b1-534c-480e-acd5-9711f850815c-1524247202159.png\" width=200>\n",
        "<br></br>\n",
        "<br></br>\n",
        "\n",
        "## *Data Science Unit 4 Sprint 3 Assignment 1*\n",
        "\n",
        "# Recurrent Neural Networks and Long Short Term Memory (LSTM)\n",
        "\n",
        "![Monkey at a typewriter](https://upload.wikimedia.org/wikipedia/commons/thumb/3/3c/Chimpanzee_seated_at_typewriter.jpg/603px-Chimpanzee_seated_at_typewriter.jpg)\n",
        "\n",
        "It is said that [infinite monkeys typing for an infinite amount of time](https://en.wikipedia.org/wiki/Infinite_monkey_theorem) will eventually type, among other things, the complete works of Wiliam Shakespeare. Let's see if we can get there a bit faster, with the power of Recurrent Neural Networks and LSTM.\n",
        "\n",
        "This text file contains the complete works of Shakespeare: https://www.gutenberg.org/files/100/100-0.txt\n",
        "\n",
        "Use it as training data for an RNN - you can keep it simple and train character level, and that is suggested as an initial approach.\n",
        "\n",
        "Then, use that trained RNN to generate Shakespearean-ish text. Your goal - a function that can take, as an argument, the size of text (e.g. number of characters or lines) to generate, and returns generated text of that size.\n",
        "\n",
        "Note - Shakespeare wrote an awful lot. It's OK, especially initially, to sample/use smaller data and parameters, so you can have a tighter feedback loop when you're trying to get things running. Then, once you've got a proof of concept - start pushing it more!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKs_s9XgVORF",
        "colab_type": "text"
      },
      "source": [
        "# Method 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ltj1je1fp5rO",
        "colab": {}
      },
      "source": [
        "# TODO - Words, words, mere words, no matter from the heart."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nb75G_Hj52oK",
        "colab_type": "code",
        "outputId": "e16871c7-7c54-4d30-a3ac-3a80ac2ddb38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install tensorflow==2.0.0"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/0f/7bd55361168bb32796b360ad15a25de6966c9c1beb58a8e30c01c8279862/tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (86.3MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3MB 47kB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.18.2)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 42.9MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 42.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.34.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.9.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.10.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.2.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.0.8)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.12.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.2.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.21.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.7.2)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (46.0.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.0.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0) (2.8.0)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.2.8)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.3.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.6/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.0)\n",
            "\u001b[31mERROR: tensorflow-federated 0.12.0 has requirement tensorflow~=2.1.0, but you'll have tensorflow 2.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-federated 0.12.0 has requirement tensorflow-addons~=0.7.0, but you'll have tensorflow-addons 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_core",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sgeGdc6B5slr",
        "colab_type": "code",
        "outputId": "6305a1fb-bb73-4cf8-d113-5596f13e5333",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# import libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import os\n",
        "\n",
        "print(tf.__version__)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yX5163pb8t6Z",
        "colab_type": "code",
        "outputId": "0d3a0e97-34e4-4663-834c-c5ecd6632216",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# import zipped text file\n",
        "from zipfile import ZipFile\n",
        "\n",
        "file_name = \"/content/text.zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7Yo4yAE9DJ_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_files = os.listdir('/content/text')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vpM89KVF9HdZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read in Data\n",
        "\n",
        "data = []\n",
        "\n",
        "for file in data_files:\n",
        "    if file[-3:] == 'txt':\n",
        "        with open(f'./text/{file}', 'r', encoding='utf-8') as f:\n",
        "            data.append(f.read())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqT-ZCDO9Mvk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode Data as Chars\n",
        "\n",
        "# Gather all text \n",
        "# Why? 1. See all possible characters 2. For training / splitting later\n",
        "text = \" \".join(data)\n",
        "\n",
        "# Unique Characters\n",
        "chars = list(set(text))\n",
        "\n",
        "# Lookup Tables\n",
        "char_int = {c:i for i, c in enumerate(chars)} \n",
        "int_char = {i:c for i, c in enumerate(chars)} "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izgIYUTT9u2f",
        "colab_type": "code",
        "outputId": "694f89d5-dfe9-43a6-cf9c-4040ff0db1cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(chars)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "107"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cm44Lur29uwU",
        "colab_type": "code",
        "outputId": "21decd3b-0acc-45b6-ae47-58f6a5abd17f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Create the sequence data\n",
        "\n",
        "maxlen = 40\n",
        "step = 5\n",
        "\n",
        "encoded = [char_int[c] for c in text]\n",
        "\n",
        "sequences = [] # Each element is 40 chars long\n",
        "next_char = [] # One element for each sequence\n",
        "\n",
        "for i in range(0, len(encoded) - maxlen, step):\n",
        "    \n",
        "    sequences.append(encoded[i : i + maxlen])\n",
        "    next_char.append(encoded[i + maxlen])\n",
        "    \n",
        "print('sequences: ', len(sequences))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sequences:  1114623\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOw7zUAU9utw",
        "colab_type": "code",
        "outputId": "34aa2c9e-0ae3-47bb-d295-7741755abebc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        }
      },
      "source": [
        "sequences[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[47,\n",
              " 72,\n",
              " 8,\n",
              " 46,\n",
              " 51,\n",
              " 64,\n",
              " 65,\n",
              " 13,\n",
              " 40,\n",
              " 19,\n",
              " 33,\n",
              " 35,\n",
              " 40,\n",
              " 65,\n",
              " 39,\n",
              " 74,\n",
              " 65,\n",
              " 46,\n",
              " 60,\n",
              " 11,\n",
              " 31,\n",
              " 19,\n",
              " 104,\n",
              " 66,\n",
              " 65,\n",
              " 19,\n",
              " 16,\n",
              " 51,\n",
              " 58,\n",
              " 43,\n",
              " 41,\n",
              " 65,\n",
              " 40,\n",
              " 65,\n",
              " 19,\n",
              " 102,\n",
              " 51,\n",
              " 46,\n",
              " 49,\n",
              " 31]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XhnFS0Gw922M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create x & y\n",
        "\n",
        "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sequences),len(chars)), dtype=np.bool)\n",
        "\n",
        "for i, sequence in enumerate(sequences):\n",
        "    for t, char in enumerate(sequence):\n",
        "        x[i,t,char] = 1\n",
        "        \n",
        "    y[i, next_char[i]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U-mEwD3-H3W",
        "colab_type": "code",
        "outputId": "fa66f5be-c218-4797-9905-7d44eb507469",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1114623, 40, 107)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h0Dh4EdF-MRU",
        "colab_type": "code",
        "outputId": "1d588d62-d6f6-4f6b-b4a1-12f26e79b7a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1114623, 107)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ra7kkmbC-N6l",
        "colab_type": "code",
        "outputId": "cfb6fb62-cc6b-4e2f-a0b2-936afd4f21ca",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "# build the model: a single LSTM\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars)), dropout=.2))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm (LSTM)                  (None, 128)               120832    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 107)               13803     \n",
            "=================================================================\n",
            "Total params: 134,635\n",
            "Trainable params: 134,635\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rz4ebaUo-P5H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds):\n",
        "    # helper function to sample an index from a probability array\n",
        "    # Takes predictions and translates them into a character.\n",
        "    # Into a position of a chracter.\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / 1\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2vLpI8R-TXe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    \n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "    \n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    \n",
        "    generated = ''\n",
        "    \n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    \n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "    \n",
        "    for i in range(400):\n",
        "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_int[char]] = 1\n",
        "            \n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds)\n",
        "        next_char = int_char[next_index]\n",
        "        \n",
        "        sentence = sentence[1:] + next_char\n",
        "        \n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    print()\n",
        "\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sCVCDeu9-WAX",
        "colab_type": "code",
        "outputId": "ee26252f-8a90-4f26-fc4b-da50e5f972e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# fit the model\n",
        "\n",
        "model.fit(x, y,\n",
        "          batch_size=1024,\n",
        "          epochs=10,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 1114623 samples\n",
            "Epoch 1/10\n",
            "1114112/1114623 [============================>.] - ETA: 0s - loss: 2.7499\n",
            "----- Generating text after Epoch: 0\n",
            "----- Generating with seed: \"but two shirts\n",
            "  out with me, and I mean\"\n",
            "but two shirts\n",
            "  out with me, and I mean,\n",
            "      s loand moly thy ae calltht foel\n",
            " hethders ap; fapenpe noty; oo hor! UNATPLERU. Hlor Ice. mithe louahf'n.\n",
            "s  Ms nir, Aghin dorsos, yod ar Ont eiee,  yo watn ord gheis.\n",
            "Dart Phawcee fou to nou dUs not frans arertoTho; to  is iw shekoTh serings wont lo:e pfro,\n",
            "\n",
            "     Er slo kin horlas? I I  lothat yf maan; o d seit entin  I the thut\n",
            "or womesl tes, ant,  entsen hyy\n",
            "Hut t yon.\n",
            "\n",
            " CURARE. Hacgfit\n",
            "1114623/1114623 [==============================] - 1549s 1ms/sample - loss: 2.7498\n",
            "Epoch 2/10\n",
            "1114112/1114623 [============================>.] - ETA: 0s - loss: 2.3622\n",
            "----- Generating text after Epoch: 1\n",
            "----- Generating with seed: \"ich, unrevers'd, stands in effectual for\"\n",
            "ich, unrevers'd, stands in effectual for\n",
            "\n",
            "merseebll niw, of lid ghet not to thaed the this ane.\n",
            "\n",
            " ELIE.\n",
            "Ge ho shad thew ahe forser fatd ake sewes of hem; The tertme Bh thay.\n",
            "  Ar out at you wellr he hath in herods.\n",
            "   hntaly Lesch; chobll yo  pureT,\n",
            "  n surd tis thich oheu thare the guls nf less.\n",
            " hin yourpplowis’rnd.\n",
            "I geow it Ify to dea w,\n",
            "merhand he ance.\n",
            "\n",
            "FFUCPIO.. to eap ig weas med werm boecth me eed,\n",
            "    ' Epot khot bey oow, lis \n",
            "1114623/1114623 [==============================] - 1396s 1ms/sample - loss: 2.3621\n",
            "Epoch 3/10\n",
            "1114112/1114623 [============================>.] - ETA: 0s - loss: 2.2660\n",
            "----- Generating text after Epoch: 2\n",
            "----- Generating with seed: \"anquish'd doth yield\n",
            "  To those two armi\"\n",
            "anquish'd doth yield\n",
            "  To those two armienisult; apvith sover\n",
            "    Sheurfoat fuizhet on the buaetcetharlds; it lodd,\n",
            "Frver  my eruie.\n",
            "\n",
            "  AN. Thal orpcrste!\n",
            "\n",
            "ORILO.\n",
            "MABreaith beanode of pisplean.\n",
            "    He\n",
            "wile yoo tar to lunher erest dotid whye.\n",
            "But as, mintion is lep, to bece whit abe nhe.\n",
            "    ATI band lies Foldms do torwice susp,\n",
            "    sncee ond stoab;\n",
            "I nind foh mos saed on orou the len is a disware.\n",
            "  e dome oad stoten it thase asteremn o\n",
            "1114623/1114623 [==============================] - 1527s 1ms/sample - loss: 2.2660\n",
            "Epoch 4/10\n",
            "1114112/1114623 [============================>.] - ETA: 0s - loss: 2.2062\n",
            "----- Generating text after Epoch: 3\n",
            "----- Generating with seed: \" my fawn,\n",
            "    And give it food. There is\"\n",
            " my fawn,\n",
            "    And give it food. There is us ore hice eaved Hus alves.\n",
            "  ALALITFUD. Nomedo ou such st mad sut you hillubson\n",
            "And thas rowe you hate such a sondire her you, Tin thess, Iellush mast-is be.\n",
            "F Mane, aill Mo fayem’st aro'n mome, on the greald whan your and,\n",
            "   MERIUD. Madlie to me hou toort joit, Com nocen torear\n",
            "\n",
            "RUCIAL\n",
            "\n",
            "Gmy, an toontf to hy nable ird fay, All sping?\n",
            "    I  eclirt ede he wigh so so a’ll tur to thas uble\n",
            "Gow\n",
            "le\n",
            "1114623/1114623 [==============================] - 1551s 1ms/sample - loss: 2.2062\n",
            "Epoch 5/10\n",
            "1114112/1114623 [============================>.] - ETA: 0s - loss: 2.1621\n",
            "----- Generating text after Epoch: 4\n",
            "----- Generating with seed: \"That only to stand high in your account,\"\n",
            "That only to stand high in your account,\n",
            "For burgay if lor in alp of then wetLerts\n",
            "    Tidropisss of the espaty Coslebt hith.\n",
            "    If emelssidnot you, chees whithte’d Sif to that\n",
            " ATherg son stoke.\n",
            "\n",
            "RADIOUS.\n",
            "Havo, beings]\n",
            "  PUSTIRK. Troids and frrices!\n",
            "    For ere Kispecknofe siass, me nut Pacee,\n",
            "That, with wimsels a diow muse nopterust\n",
            "    Didstume tourl wall gasetllemin har cose\n",
            "\n",
            "      perEf rote of list sut no sulle\n",
            "\n",
            "hate the cunercti\n",
            "1114623/1114623 [==============================] - 1454s 1ms/sample - loss: 2.1620\n",
            "Epoch 6/10\n",
            "1114112/1114623 [============================>.] - ETA: 0s - loss: 2.1250\n",
            "----- Generating text after Epoch: 5\n",
            "----- Generating with seed: \"ccess to electronic\n",
            "works by freely shar\"\n",
            "ccess to electronic\n",
            "works by freely share proincest betire,\n",
            "An that Lith in the lomars faveless\n",
            "Bear hare hearwaice. KINGY ELOYE.—(3; leear yot the poth a beill’s lor.\n",
            "    men me ho bair! At cSoe hiv? I knace,\n",
            "Siel coon wich you Wreen this to ny winiena, I nor\n",
            "    Iuch a entere hath', gurterice.\n",
            "GoNAgDANE, Mase wo my brencebaul, it etbrnds,\n",
            "    Cad thy hortia’s hee thou s pay? That sutokel'os aun.\n",
            "And ferdean a she wiplet our wraige sor\n",
            "1114623/1114623 [==============================] - 1393s 1ms/sample - loss: 2.1250\n",
            "Epoch 7/10\n",
            "1114112/1114623 [============================>.] - ETA: 0s - loss: 2.0961\n",
            "----- Generating text after Epoch: 6\n",
            "----- Generating with seed: \",\n",
            "Due reference of place and exhibition,\"\n",
            ",\n",
            "Due reference of place and exhibition,\n",
            "silayecs wnt you sevee here -rich;\n",
            "That, parritils you has sord all of fores.\n",
            "\n",
            " YOURUST.\n",
            "How you nou medd!\n",
            "Bet that not'ded saold give saire to try live\n",
            "               2ent the and t\n",
            "  We liew is a the mentsed ue even my fors,\n",
            "You fe ritett ens buatk! nat hen will the Lokes;\n",
            "    Yod do guck portht well wise, Langedfor\n",
            "erpeard. Wher! My flyss hasing, clava\n",
            "Helly our nith midver apt teathtight;\n",
            "And\n",
            "1114623/1114623 [==============================] - 1552s 1ms/sample - loss: 2.0961\n",
            "Epoch 8/10\n",
            "1114112/1114623 [============================>.] - ETA: 0s - loss: 2.0728\n",
            "----- Generating text after Epoch: 7\n",
            "----- Generating with seed: \"eboyes) will be seene\n",
            "And quickly, yours\"\n",
            "eboyes) will be seene\n",
            "And quickly, yours I shell viusor. Weeps pieain to buppetus my eedafd.\n",
            "\n",
            "LAsCLLO.\n",
            "He wh’t’s noz, whys me som; Hy a sermcon pithie quiritel. It Beare!\n",
            "\n",
            "PALY.\n",
            "Go, lyst foubon, it mes\n",
            "    I dore they from nower the past.\n",
            "Shat at brighe fan wail hact to at nut sart\n",
            "\n",
            "   FOe Heav'stion an chercacel’d on up weet\n",
            "    Frengnst on you. Thos his faid the nreees; with morew parp!\n",
            "As ourchom he. Rade ma, me.\n",
            " HALMAN. and mast?\n",
            " \n",
            "1114623/1114623 [==============================] - 1414s 1ms/sample - loss: 2.0728\n",
            "Epoch 9/10\n",
            "1114112/1114623 [============================>.] - ETA: 0s - loss: 2.0518\n",
            "----- Generating text after Epoch: 8\n",
            "----- Generating with seed: \"rtly touching or concerning the\n",
            "discipli\"\n",
            "rtly touching or concerning the\n",
            "disciplids serdablegent;\n",
            "The rriny one siget mudwos her not out\n",
            "There aliec tank cincion youtwdysonn,\n",
            "A pracent lebss fatired shat sillder, weldey. Fords beavel,\n",
            "Ang the pirivithing cemice! whis prasest ore usstild\n",
            "tin of gie weem stase:\n",
            "    Sheifs, me for harn'd the vancelir weilty.\n",
            "  LOADES.. Hows prekety! He kneve on Mark new Seallseas?\n",
            "\n",
            "PARRIN.\n",
            "Ay, and when! Cloughtot wealk toun? Is theentare\n",
            "    you \n",
            "1114623/1114623 [==============================] - 1305s 1ms/sample - loss: 2.0518\n",
            "Epoch 10/10\n",
            "1114112/1114623 [============================>.] - ETA: 0s - loss: 2.0339\n",
            "----- Generating text after Epoch: 9\n",
            "----- Generating with seed: \"extant.\n",
            "\n",
            "EMILIA.\n",
            "The Sun grows high, let\"\n",
            "extant.\n",
            "\n",
            "EMILIA.\n",
            "The Sun grows high, let ugverrest. Cosy is to sly?\n",
            "  KING. Nay, the wornes, tell se; I aram? Phot there.\n",
            "A’ll the Dingh I wourd ut I puithes as enfeCle oo.\n",
            "Ma say. Leuglerik, acle, is thy spaccinas;\n",
            "    Whis did drok thy tolds from gook’d peafing\n",
            "    Mared in his not ourss your undlet.\n",
            "  DUALA. I Core, I lave in\n",
            "Hore uty not tarsh, and Deace Sime  ceide.\n",
            "  MOSEOFIR. If edif colloking all quele of the ener? and,\n",
            "Burblonk\n",
            "1114623/1114623 [==============================] - 1406s 1ms/sample - loss: 2.0339\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f1cba91a5f8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "zE4a4O7Bp5x1"
      },
      "source": [
        "# Resources and Stretch Goals"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uT3UV3gap9H6"
      },
      "source": [
        "## Stretch goals:\n",
        "- Refine the training and generation of text to be able to ask for different genres/styles of Shakespearean text (e.g. plays versus sonnets)\n",
        "- Train a classification model that takes text and returns which work of Shakespeare it is most likely to be from\n",
        "- Make it more performant! Many possible routes here - lean on Keras, optimize the code, and/or use more resources (AWS, etc.)\n",
        "- Revisit the news example from class, and improve it - use categories or tags to refine the model/generation, or train a news classifier\n",
        "- Run on bigger, better data\n",
        "\n",
        "## Resources:\n",
        "- [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) - a seminal writeup demonstrating a simple but effective character-level NLP RNN\n",
        "- [Simple NumPy implementation of RNN](https://github.com/JY-Yoon/RNN-Implementation-using-NumPy/blob/master/RNN%20Implementation%20using%20NumPy.ipynb) - Python 3 version of the code from \"Unreasonable Effectiveness\"\n",
        "- [TensorFlow RNN Tutorial](https://github.com/tensorflow/models/tree/master/tutorials/rnn) - code for training a RNN on the Penn Tree Bank language dataset\n",
        "- [4 part tutorial on RNN](http://www.wildml.com/2015/09/recurrent-neural-networks-tutorial-part-1-introduction-to-rnns/) - relates RNN to the vanishing gradient problem, and provides example implementation\n",
        "- [RNN training tips and tricks](https://github.com/karpathy/char-rnn#tips-and-tricks) - some rules of thumb for parameterizing and training your RNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mY8r1BA3VXD1",
        "colab_type": "text"
      },
      "source": [
        "# Method 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O470alV-VrIz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "864ffdd1-b110-4d45-e272-f18ebfb538a1"
      },
      "source": [
        "!pip install tensorflow==2.0.0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/46/0f/7bd55361168bb32796b360ad15a25de6966c9c1beb58a8e30c01c8279862/tensorflow-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (86.3MB)\n",
            "\u001b[K     |████████████████████████████████| 86.3MB 77kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.0.8)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.9.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.12.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.2.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (3.10.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.34.2)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.12.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.8.1)\n",
            "Collecting tensorboard<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/76/54/99b9d5d52d5cb732f099baaaf7740403e83fe6b0cedde940fabd2b13d75a/tensorboard-2.0.2-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 36.6MB/s \n",
            "\u001b[?25hCollecting tensorflow-estimator<2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/08/8b927337b7019c374719145d1dceba21a8bb909b93b1ad6f8fb7d22c1ca1/tensorflow_estimator-2.0.1-py2.py3-none-any.whl (449kB)\n",
            "\u001b[K     |████████████████████████████████| 450kB 60.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (1.18.2)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.2.0)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==2.0.0) (0.2.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==2.0.0) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==2.0.0) (46.0.0)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.7.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.21.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.2.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.0.0)\n",
            "Requirement already satisfied: cachetools<3.2,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.1)\n",
            "Requirement already satisfied: rsa<4.1,>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (4.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3,>=2.21.0->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (1.24.3)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<4.1,>=3.1.4->google-auth<2,>=1.6.3->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.1.0,>=2.0.0->tensorflow==2.0.0) (3.1.0)\n",
            "\u001b[31mERROR: tensorflow-federated 0.12.0 has requirement tensorflow~=2.1.0, but you'll have tensorflow 2.0.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: tensorflow-federated 0.12.0 has requirement tensorflow-addons~=0.7.0, but you'll have tensorflow-addons 0.8.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: tensorboard, tensorflow-estimator, tensorflow\n",
            "  Found existing installation: tensorboard 1.15.0\n",
            "    Uninstalling tensorboard-1.15.0:\n",
            "      Successfully uninstalled tensorboard-1.15.0\n",
            "  Found existing installation: tensorflow-estimator 1.15.1\n",
            "    Uninstalling tensorflow-estimator-1.15.1:\n",
            "      Successfully uninstalled tensorflow-estimator-1.15.1\n",
            "  Found existing installation: tensorflow 1.15.0\n",
            "    Uninstalling tensorflow-1.15.0:\n",
            "      Successfully uninstalled tensorflow-1.15.0\n",
            "Successfully installed tensorboard-2.1.1 tensorflow-2.1.0 tensorflow-estimator-2.1.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_core",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yAQLPU4JVkVW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9cfc491b-0712-4230-fafd-b369a8f14d90"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "print(tf.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.0.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a18PnMakVnhO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "012a5504-4710-44c3-c33f-959409157db9"
      },
      "source": [
        "### Words, words, mere words, no matter from the heart.\n",
        "url = 'https://www.gutenberg.org/files/100/100-0.txt'\n",
        "filepath = tf.keras.utils.get_file(fname='shakespeare.txt',\n",
        "                                   origin=url)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.gutenberg.org/files/100/100-0.txt\n",
            "5783552/5777367 [==============================] - 1s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urnJ-HzMV_gW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# open full text via file path\n",
        "full_text = open(filepath, 'r', encoding='utf-8-sig').read()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b2rST9cDWDCt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sonnets in list form\n",
        "sonnets = full_text[2771:101122]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59PZMq0iWJQY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocess(text):\n",
        "    text = ' '.join(text.split())\n",
        "    return text"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MFvBrkN6WRLO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sonnets = preprocess(sonnets)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBG1VWhEWSxM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "b7f5e9f8-a2f0-46a4-96e9-92e42194f80a"
      },
      "source": [
        "# Identify unique characters.\n",
        "chars = sorted(set(sonnets))\n",
        "' '.join(chars)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'  ! ( ) , - . 0 1 2 3 4 5 6 7 8 9 : ; ? A B C D E F G H I J K L M N O P R S T U V W Y a b c d e f g h i j k l m n o p q r s t u v w x y z ‘ ’'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEkwzCuEWVjM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create mapping of unique chars to integers and vice versa\n",
        "char_to_index = {c:i for i, c in enumerate(chars)}\n",
        "index_to_char = {i:c for i, c in enumerate(chars)}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuQWl-7YWdJI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "721fada7-83f0-472a-83b6-8e712857be74"
      },
      "source": [
        "n_chars = len(sonnets)\n",
        "n_vocab = len(chars)\n",
        "print ('Total Characters:', n_chars)\n",
        "print ('Unique Characters:', n_vocab)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters: 94192\n",
            "Unique Characters: 71\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_prtVkMjWgCk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "858d0aab-68e7-4f36-caa0-fcce996e1a8c"
      },
      "source": [
        "# Generate the sequence data.\n",
        "\n",
        "maxlen = 40\n",
        "steps = 3\n",
        "\n",
        "subsequences = [] # X \n",
        "next_chars = [] # Y\n",
        "\n",
        "for i in range(0, len(sonnets) - maxlen, steps):\n",
        "    subsequences.append(sonnets[i : i + maxlen])\n",
        "    next_chars.append(sonnets[i + maxlen])\n",
        "\n",
        "print ('Number of subsequences:', len(subsequences))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of subsequences: 31384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubg-9s5fWiJd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "b3b18f1a-74de-4b9a-f026-f8015e4513f9"
      },
      "source": [
        "print(\"sub 0: \", subsequences[0])\n",
        "print(\"sub 1: \", subsequences[1]) "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sub 0:  THE SONNETS 1 From fairest creatures we \n",
            "sub 1:   SONNETS 1 From fairest creatures we des\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9f3xBzZ8Wj5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Specify x & y.\n",
        "x = np.zeros((len(subsequences), maxlen, len(chars)),\n",
        "             dtype=np.bool)\n",
        "y = np.zeros((len(subsequences), len(chars)), \n",
        "             dtype=np.bool)\n",
        "\n",
        "for i, subsequence in enumerate(subsequences):\n",
        "    for t, char in enumerate(subsequence):\n",
        "        x[i, t, char_to_index[char]] = 1\n",
        "        \n",
        "    y[i, char_to_index[next_chars[i]]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGooq5TyWyZB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "867f7aee-b593-41bd-de51-7e14a5d3cbe0"
      },
      "source": [
        "# x shape\n",
        "x.shape"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31384, 40, 71)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5f4CNKpW0YK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "304ab857-10e8-4119-8cb1-79c67205e3dc"
      },
      "source": [
        "# y shape\n",
        "y.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(31384, 71)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QcbEngy5W2Rp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Build the model: a single LSTM\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars))))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "optimizer = RMSprop()\n",
        "model.compile(loss='categorical_crossentropy', optimizer=optimizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ITZsKERW6KX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds, temperature=1.0):\n",
        "    \"\"\"\n",
        "    Helper function to sample an index from a probability array.\n",
        "    \"\"\"\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / temperature\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXkXFBJRW7qD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def on_epoch_end(epoch, _):\n",
        "    \"\"\"\n",
        "    Function invoked at end of each epoch. Prints generated text.\n",
        "    \"\"\"\n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "\n",
        "    start_index = random.randint(0, len(sonnets) - maxlen - 1)\n",
        "    for diversity in [0.2, 0.5, 1.0, 1.2]:\n",
        "        print('----- diversity:', diversity)\n",
        "\n",
        "        generated = ''\n",
        "        subsequence = sonnets[start_index: start_index + maxlen]\n",
        "        generated += subsequence\n",
        "        print('----- Generating with seed: \"' + subsequence + '\"')\n",
        "        sys.stdout.write(generated)\n",
        "\n",
        "        for i in range(400):\n",
        "            x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "            for t, char in enumerate(subsequence):\n",
        "                x_pred[0, t, char_to_index[char]] = 1.\n",
        "\n",
        "            preds = model.predict(x_pred, verbose=0)[0]\n",
        "            next_index = sample(preds, diversity)\n",
        "            next_char = index_to_char[next_index]\n",
        "\n",
        "            subsequence = subsequence[1:] + next_char\n",
        "\n",
        "            sys.stdout.write(next_char)\n",
        "            sys.stdout.flush()\n",
        "        print()\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vk3O7TiWW-MZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "202eb40f-b2a4-4c28-a52b-86d8b8414a19"
      },
      "source": [
        "# fit model\n",
        "model.fit(x, y,\n",
        "          batch_size=128,\n",
        "          epochs=5,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 31384 samples\n",
            "Epoch 1/5\n",
            "31360/31384 [============================>.] - ETA: 0s - loss: 3.0021\n",
            "----- Generating text after Epoch: 0\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"earing sight, Serving with looks his sac\"\n",
            "earing sight, Serving with looks his sace ce  ie  ee  oe  oe  ee  e e  oe  ie  ae  o e  o  he  he  oe  eh  eh oe  e ee  on  e  e e de t i e e e  oe  ae  e  ee  he e  ho  the  ee  ee th e e  he  oe  ee  ee  oe  t  ee  he  ae  ee  ei ie e e  oe  en  e  he re  e  e e ie  oe  te  e ee  ee  tee  ee  he e  e e e e re  oe  oe e  he  he  he  e i ie  ie  ee  ee  o  oe  he  ee he  he  e  ee  oe  iee  ee  he  he  to  e e ee e ee  ee   oe e  ee e e\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"earing sight, Serving with looks his sac\"\n",
            "earing sight, Serving with looks his sac sie e riei cee  ehe  diey  reei ahe nd ieo  te tey tolr e te re bh a  gy ce ie ader hreat feo se ae hi sooe d e haee  oee  wor  ar  o eo  ol bhe tan e h e tben r fr  me in   od me ma lee s cAs f it ee  ge he thh oe whe t e ih arn  ef e hee eey  he iits ee de  e  eh  ee  be eaee  i ai hie eiti et st ao ner  is orte iee  eh  oein t lo  nie en h aee pae lo e  te e tee lh we  re fo he  ar  o eay we  \n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"earing sight, Serving with looks his sac\"\n",
            "earing sight, Serving with looks his sac’o vagcri piybsc(lnrdBts(, h,dpon feed? ay1 arichg h lh y it h. a oz2 n hulmme  hect ,re ee  mefahn etg ir eb cfen, esnerlaemye letee fewr  hbe ,te n deofoveen- ueaPlea y,t il  boyiglyfledkythwhe osoes Yi tmd   ssh.dsniwI ndcs oNuns dmhs tsa y wle:  wernlvleo r rio tihn dnnesyk emm  eveAy iaori iiuthSe se arihiri o e  dhbtire eea,tnn wsgtrvDsiboo yhecfebht oGhy n ldivei dl oiwtebae,pparil r iwrnn,\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"earing sight, Serving with looks his sac\"\n",
            "earing sight, Serving with looks his sacim c qofdshtv8rais ?.cc,btIe endO, unlsd xrfpootth  eotsBesn Isee cingaddsdhrbeg yW ui car di,Okr tusaco eh thdr,othprIiyf,ub rr  beys mdedtqe ,fserei:hl iriimtino hotgdotel-nt o’bTrhk wyu ih TeesuknlA.aax ei mouihsTe  nf:reetr4.u cht eS  hymrsl. ,Nll mI idey er Aewi nrp,p teopnkehm, ’ e kervi,l mne dcna eCIOowIfdoua  aoeruev vhg ms aic .len hdl stedelregpau.alu fTetn vT f, wsbag’ui pe rn dhaasemy\n",
            "31384/31384 [==============================] - 101s 3ms/sample - loss: 3.0023\n",
            "Epoch 2/5\n",
            "31360/31384 [============================>.] - ETA: 0s - loss: 2.6432\n",
            "----- Generating text after Epoch: 1\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"d painting need, And therefore to your f\"\n",
            "d painting need, And therefore to your fo the the th the se so the the the se the se the th the se the the the s the the the th the the se the the s the sat se the se the s the so th s the the s th the s the se th the se the se the the the the s the th the the th me the se the se the so s th the s th se sh se th the se the the the the the th th me se th the se the the the s the the se the se th se the s the se mo th th me the se se the \n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"d painting need, And therefore to your f\"\n",
            "d painting need, And therefore to your fo soto  fo me eres bod se as s ths fa ths hn th mr eu bate hi me sem, sin be th ee sh lo the may th mf foe se th sot an the thse tha se, bo the tha e the the t so, whe be s se tho the to he re the th th alt s ire th tir se sh me the ser mes sslt or the ee me so set th to ther  y se so noe ne th the th th be me sat cos ther se th the the th, th tour the wos tir the se se ll ar the the t o me les no\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"d painting need, And therefore to your f\"\n",
            "d painting need, And therefore to your fe ih .,, tan heet, ds ma ane bihr Sore mt ait ses mhsy rpye myo s  ael fhpa, bss ate ad li, cdt ds towty sitmpess  isosetMrveb ’anucTre bnI Whuli,e, ie bilg me iweo Thokslis., ein, ntas celptlascb I oosun, .Esos smactmy , whed cor )aute sd,  al g dod, At sl swin, chpd Iury ?n it Wey th v, tog Lh Aaer, mriln fe sol mS, os, fry becrddddeet theot crean’ madirtny Sid sdem temyt nd tord dian ,, snseets\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"d painting need, And therefore to your f\"\n",
            "d painting need, And therefore to your feg y oe,  rht saatg spadlmd.liht; tbess ooesnThe gToncb’nc aamse ut’,e’fd1I n AheaT Tie h uit  f: Fy foastfdug.sr’es Tea rO mfh  hs  llt kat, Nhu th oo I iory ,m IyIfqh: nact aw the sgneer mtveing pmr,g, eIs hyntisfTrois o h, Aa sasOy :th: clthase, Mo tabr su tpe Bsg ts eMiI. Wy-pre.Wkn yb. TFe de  ads biL.s Wo  or tap to th th nsesrd4 -oinatss .ct them ty, he, sos torrc sll Is. sol gha or arny Th\n",
            "31384/31384 [==============================] - 98s 3ms/sample - loss: 2.6430\n",
            "Epoch 3/5\n",
            "31360/31384 [============================>.] - ETA: 0s - loss: 2.4088\n",
            "----- Generating text after Epoch: 2\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"no leisure taken To weigh how once I suf\"\n",
            "no leisure taken To weigh how once I suf the s ou th th th th s th s th th s an th th th se th th s th th se she th th th th the s an th th me th th se the s be the s the the she th th the she she the the the the s an the s an th th s the th th se th th th th se the th th th th th th th th th the she the th the s the th th se the th th th th th th th th th sh th th se the th th th th se se th th s the s the th th th th s the th th th se\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"no leisure taken To weigh how once I suf\"\n",
            "no leisure taken To weigh how once I suf the I the he tho th th se be bee shert end the he the be the su be out se sos mo the  lou than he be the, by de fee the st bat th  ou the (h se ser on the d duty she the pan the sin share snt Whe s an ind s in fove th s the sl the th th w ch th th wh th st an the Fe th il th the eo the s the be le th s the, Tho bo d me the s th ou sh the an so se so the the th t ou the th sar so the pes an dh the\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"no leisure taken To weigh how once I suf\"\n",
            "no leisure taken To weigh how once I suf sh tfen Tes oi eld jod ded shlr aun se soudEb sigh bud, Sh tl tht : th lf lhen co. thy put . th sere’d An tiy  ho  hnasd h u weiu, Thauf ther-sir’co m lo wh mo fo be sy biin 2out yive chowt  we dor, et oue dve suybezy bd lh fro shat Toe , Cay se mo  ine, N SindI Ag thin rad th sf Ald sles Tho th sg sh hoen ses’sthd Ad du gh elos so re rom; whido fot pnthe gog  ulledb sh kiin s woe olt imeond rsde\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"no leisure taken To weigh how once I suf\"\n",
            "no leisure taken To weigh how once I sufln’vh nde Tivne y bearetsxms Mths tuu0dkmndseI Br ioC Weo glss oils, ad Whoon, Morl at, Bht ve mon mord theerr’: 4or  miard I bnlitleCitgAoMvtt-ou mh wus los th lo SounB, Bos me, le-f iaaw th, gagh sou? tho ri’Nt Sni v nl  ha linl : pmhe Fhc rer ms somek A , hid ch solid Ao4 ce dnd oy hovcme thfs biile. Wh unpo whoud foll lien fhu the gr vervI inar . hvSro ghave Tha. sir thu, Bon, Sohedh Tat 3pfae\n",
            "31384/31384 [==============================] - 107s 3ms/sample - loss: 2.4088\n",
            "Epoch 4/5\n",
            "31360/31384 [============================>.] - ETA: 0s - loss: 2.2911\n",
            "----- Generating text after Epoch: 3\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \"ummer’s flower is to the summer sweet, T\"\n",
            "ummer’s flower is to the summer sweet, Tho the thar the the than than south what the thar thangind that on that the thing the than the thas than the the that sout the the wing the thou the than the thar the the the than that than that the the thar that thou thou thou thou wor the wore thou thou thou hout the that the ther outh the thar thou thar that the the the than the than the thar south the than the the the the the the than thou tha\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \"ummer’s flower is to the summer sweet, T\"\n",
            "ummer’s flower is to the summer sweet, Thove tham your mour thar and theut thour soor whand thand An pous the ard that thou sath in thin thou doud wor weid be ore outh rome beden than thane uith than andore thee me forod wond thed setind when the thar besere, To de thous on hey orond I ar doul, And my th thee ding bes ord mo fore that fath wile wore foing the wiit th whan th th eime thr shet theat end ther int mes sill be south, And or \n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \"ummer’s flower is to the summer sweet, T\"\n",
            "ummer’s flower is to the summer sweet, Thanlo timggur thae fere thend oucs thfureng, jons doccher lorn, arld, lon thmresssangys ar thahis ther: Andoney ceatu helcseeAs ar ymound ar ond arsror inld nle ilt, Whtt mis ypcee, on dony saf es cais, Ap2 hever. 0urkomttand ’ellmtrel, yof hourece, y Iurfsy ind xating lpind thput tyered thiid to bereond ban com? heoth ghast fad betorsv thore uo tout yuro thaled. Ar weoneftuligg irt nive tile sone\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \"ummer’s flower is to the summer sweet, T\"\n",
            "ummer’s flower is to the summer sweet, T tuindoutd Fatsf d lar, I 1hvastSugh lhearsky. ff ilh mfopwond ang: nof thy jorl nndsd of ied meson, ninp hithuo fnor ath this mamt ousr, Bcin dhae soradn inar fart ;uan bonm coord4, Wibg wfos hor b styonurgfatnus-, atheca masts, On thos thpeesdrrrtgur inost-s arlpabeprshmt it iwithe 5nd sur homdy nn kly iot  fianew ou, Thonf thalk iwesshos, Oo fined  orte co)ule athacg ur pyed.  clalm sat ulive u\n",
            "31384/31384 [==============================] - 107s 3ms/sample - loss: 2.2913\n",
            "Epoch 5/5\n",
            "31360/31384 [============================>.] - ETA: 0s - loss: 2.2174\n",
            "----- Generating text after Epoch: 4\n",
            "----- diversity: 0.2\n",
            "----- Generating with seed: \" feathers to the learned’s wing, And giv\"\n",
            " feathers to the learned’s wing, And give thee south thee sore thou the sall thee that thou thou tout an the seare thee thou sour the thear than thee in thou sore thee thee wore thou thar thee the the that seath the sore tout the seing the the the thee sore than the than the seand the sour thee thee south the than thou the thee thou soure south thau thou southe thee thee thee south the thee sore thou the sore theat ou the searend thee t\n",
            "----- diversity: 0.5\n",
            "----- Generating with seed: \" feathers to the learned’s wing, And giv\"\n",
            " feathers to the learned’s wing, And give weat fot thin are poll thou hove buth yo past ou toun soul mo ware I outh an that do thoun do chee the some dout thiag beest thee in thou loul to lo heace thar beapt ous fos win ou thou thee sored ou whin the the thar thou sot the ther more, wot the thou tham theut me theal seath nous out soul ande, And the wing mear soalt thou thave sore that an then ares ard thin and more whoul in thing sear s\n",
            "----- diversity: 1.0\n",
            "----- Generating with seed: \" feathers to the learned’s wing, And giv\"\n",
            " feathers to the learned’s wing, And give wofmange movt ious rove fail woms wor’ssese. A! On tho chareveresmese thavorh marr athongith retin iI leawe syescwond oues, rhit theipril shasp tavey fvills . And ouin deeling apy katf hos yor aind th my walo beud fheam sevens weathico thime stawe il may oas woet on beaseeas byoued mad’vaf art mafs ay And hawe the sbreingent toe for uies I oreet protr igereut dist hrinos dothkn weyt, whouFore os\n",
            "----- diversity: 1.2\n",
            "----- Generating with seed: \" feathers to the learned’s wing, And giv\"\n",
            " feathers to the learned’s wing, And givt muly aureseHcusglfmeakkse gate’fens wokbut theme lomcey’? teende. Oot neom pay torue’as tipwyo benous ord scmil qur ottene urrmeme I uls tens aiky inuhrs Bos opwond, o3 thaxginh oe siseturlsdetd, Sorthardl unomavetuom Cpanlreae, Fo ttoow to thu thee1r’t kofso llethes orengt sath thoulg aullt’fed, bond eboy’m to crais of thys wavipsout low. Kata beo eico soresimy breed ay. Amd Beou’ata y wealing \n",
            "31384/31384 [==============================] - 109s 3ms/sample - loss: 2.2174\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0e2d47c0f0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y7_gCpTbXB_g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
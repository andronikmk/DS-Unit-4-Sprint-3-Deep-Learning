{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "LS_DS_431_RNN_and_LSTM_Lecture.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "U4-S3-DL (Python3)",
      "language": "python",
      "name": "u4-s2-dl"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.0"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andronikmk/DS-Unit-4-Sprint-3-Deep-Learning/blob/master/module1-rnn-and-lstm/LS_DS_431_RNN_and_LSTM_Lecture.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "Ldr0HZ193GKb"
      },
      "source": [
        "Lambda School Data Science\n",
        "\n",
        "*Unit 4, Sprint 3, Module 1*\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzZ1YNjVvaas",
        "colab_type": "text"
      },
      "source": [
        "# Recurrent Neural Networks (RNNs) and Long Short Term Memory (LSTM) (Prepare)\n",
        "\n",
        "<img src=\"https://media.giphy.com/media/l2JJu8U8SoHhQEnoQ/giphy.gif\" width=480 height=356>\n",
        "<br></br>\n",
        "<br></br>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pREGTTiTvaau",
        "colab_type": "text"
      },
      "source": [
        "## Learning Objectives\n",
        "- <a href=\"#p1\">Part 1: </a>Describe Neural Networks used for modeling sequences\n",
        "- <a href=\"#p2\">Part 2: </a>Apply a LSTM to a text generation problem using Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "_IizNKWLomoA"
      },
      "source": [
        "## Overview\n",
        "\n",
        "> \"Yesterday's just a memory - tomorrow is never what it's supposed to be.\" -- Bob Dylan\n",
        "\n",
        "Wish you could save [Time In A Bottle](https://www.youtube.com/watch?v=AnWWj6xOleY)? With statistics you can do the next best thing - understand how data varies over time (or any sequential order), and use the order/time dimension predictively.\n",
        "\n",
        "A sequence is just any enumerated collection - order counts, and repetition is allowed. Python lists are a good elemental example - `[1, 2, 2, -1]` is a valid list, and is different from `[1, 2, -1, 2]`. The data structures we tend to use (e.g. NumPy arrays) are often built on this fundamental structure.\n",
        "\n",
        "A time series is data where you have not just the order but some actual continuous marker for where they lie \"in time\" - this could be a date, a timestamp, [Unix time](https://en.wikipedia.org/wiki/Unix_time), or something else. All time series are also sequences, and for some techniques you may just consider their order and not \"how far apart\" the entries are (if you have particularly consistent data collected at regular intervals it may not matter)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "44QZgrPUe3-Y"
      },
      "source": [
        "# Neural Networks for Sequences (Learn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "8C8ZyOayvaa0"
      },
      "source": [
        "## Overview\n",
        "\n",
        "There's plenty more to \"traditional\" time series, but the latest and greatest technique for sequence data is recurrent neural networks. A recurrence relation in math is an equation that uses recursion to define a sequence - a famous example is the Fibonacci numbers:\n",
        "\n",
        "$F_n = F_{n-1} + F_{n-2}$\n",
        "\n",
        "For formal math you also need a base case $F_0=1, F_1=1$, and then the rest builds from there. But for neural networks what we're really talking about are loops:\n",
        "\n",
        "![Recurrent neural network](https://upload.wikimedia.org/wikipedia/commons/b/b5/Recurrent_neural_network_unfold.svg)\n",
        "\n",
        "The hidden layers have edges (output) going back to their own input - this loop means that for any time `t` the training is at least partly based on the output from time `t-1`. The entire network is being represented on the left, and you can unfold the network explicitly to see how it behaves at any given `t`.\n",
        "\n",
        "Different units can have this \"loop\", but a particularly successful one is the long short-term memory unit (LSTM):\n",
        "\n",
        "![Long short-term memory unit](https://upload.wikimedia.org/wikipedia/commons/thumb/6/63/Long_Short-Term_Memory.svg/1024px-Long_Short-Term_Memory.svg.png)\n",
        "\n",
        "There's a lot going on here - in a nutshell, the calculus still works out and backpropagation can still be implemented. The advantage (ane namesake) of LSTM is that it can generally put more weight on recent (short-term) events while not completely losing older (long-term) information.\n",
        "\n",
        "After enough iterations, a typical neural network will start calculating prior gradients that are so small they effectively become zero - this is the [vanishing gradient problem](https://en.wikipedia.org/wiki/Vanishing_gradient_problem), and is what RNN with LSTM addresses. Pay special attention to the $c_t$ parameters and how they pass through the unit to get an intuition for how this problem is solved.\n",
        "\n",
        "So why are these cool? One particularly compelling application is actually not time series but language modeling - language is inherently ordered data (letters/words go one after another, and the order *matters*). [The Unreasonable Effectiveness of Recurrent Neural Networks](https://karpathy.github.io/2015/05/21/rnn-effectiveness/) is a famous and worth reading blog post on this topic.\n",
        "\n",
        "For our purposes, let's use TensorFlow and Keras to train RNNs with natural language. Resources:\n",
        "\n",
        "- https://github.com/keras-team/keras/blob/master/examples/imdb_lstm.py\n",
        "- https://keras.io/layers/recurrent/#lstm\n",
        "- http://adventuresinmachinelearning.com/keras-lstm-tutorial/\n",
        "\n",
        "Note that `tensorflow.contrib` [also has an implementation of RNN/LSTM](https://www.tensorflow.org/tutorials/sequences/recurrent)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "eWrQllf8WEd-"
      },
      "source": [
        "## Follow Along\n",
        "\n",
        "Sequences come in many shapes and forms from stock prices to text. We'll focus on text, because modeling text as a sequence is a strength of Neural Networks. Let's start with a simple classification task using a TensorFlow tutorial. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "TqgaAFHQvaa3"
      },
      "source": [
        "### RNN/LSTM Sentiment Classification with Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wW5ft6Yavaa5",
        "colab_type": "text"
      },
      "source": [
        "Make sure you are familiar with this classic examples!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Ti23G0gRe3kr",
        "outputId": "bba9ae40-a286-49ed-d87b-b2946fb60ddf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 975
        }
      },
      "source": [
        "'''\n",
        "#Trains an LSTM model on the IMDB sentiment classification task.\n",
        "The dataset is actually too small for LSTM to be of any advantage\n",
        "compared to simpler, much faster methods such as TF-IDF + LogReg.\n",
        "**Notes**\n",
        "- RNNs are tricky. Choice of batch size is important,\n",
        "choice of loss and optimizer is critical, etc.\n",
        "Some configurations won't converge.\n",
        "- LSTM loss decrease patterns during training can be quite different\n",
        "from what you see with CNNs/MLPs/etc.\n",
        "'''\n",
        "from __future__ import print_function\n",
        "\n",
        "from tensorflow.keras.preprocessing import sequence\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Embedding\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.datasets import imdb\n",
        "\n",
        "max_features = 20000 # only going to look at the 20000 most popular works.\n",
        "# cut texts after this number of words (among top max_features most common words)\n",
        "maxlen = 80\n",
        "batch_size = 32\n",
        "\n",
        "print('Loading data...')\n",
        "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words=max_features)\n",
        "print(len(x_train), 'train sequences')\n",
        "print(len(x_test), 'test sequences')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb.npz\n",
            "17465344/17464789 [==============================] - 3s 0us/step\n",
            "25000 train sequences\n",
            "25000 test sequences\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0ME06WGvabD",
        "colab_type": "code",
        "outputId": "9ef83bf4-6731-4022-822b-f791d6edaf3a",
        "colab": {}
      },
      "source": [
        "x_train[0][:10] # these numbers represent words"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FbayOdqGvabJ",
        "colab_type": "code",
        "outputId": "69e3cf6f-5dde-475e-f211-787cffe04de8",
        "colab": {}
      },
      "source": [
        "print('Pad Sequences (samples x time)')\n",
        "\n",
        "# takes sequence makes makes sure its not to long or too short.\n",
        "x_train = sequence.pad_sequences(x_train, maxlen=maxlen)\n",
        "x_test = sequence.pad_sequences(x_test, maxlen=maxlen)\n",
        "\n",
        "print('x_train shape: ', x_train.shape)\n",
        "print('x_test shape: ', x_test.shape)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pad Sequences (samples x time)\n",
            "x_train shape:  (25000, 80)\n",
            "x_test shape:  (25000, 80)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C2f5QMsGvabO",
        "colab_type": "code",
        "outputId": "fc7018a1-e431-4e89-cebb-00917cc12478",
        "colab": {}
      },
      "source": [
        "x_train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([   15,   256,     4,     2,     7,  3766,     5,   723,    36,\n",
              "          71,    43,   530,   476,    26,   400,   317,    46,     7,\n",
              "           4, 12118,  1029,    13,   104,    88,     4,   381,    15,\n",
              "         297,    98,    32,  2071,    56,    26,   141,     6,   194,\n",
              "        7486,    18,     4,   226,    22,    21,   134,   476,    26,\n",
              "         480,     5,   144,    30,  5535,    18,    51,    36,    28,\n",
              "         224,    92,    25,   104,     4,   226,    65,    16,    38,\n",
              "        1334,    88,    12,    16,   283,     5,    16,  4472,   113,\n",
              "         103,    32,    15,    16,  5345,    19,   178,    32],\n",
              "      dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sPHXr3NjvabW",
        "colab_type": "code",
        "outputId": "05ea1671-5494-4834-ec17-291909082b69",
        "colab": {}
      },
      "source": [
        "y_train[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9mhQe1Avabb",
        "colab_type": "code",
        "outputId": "e5743044-6a37-4fe4-aa47-488da338de69",
        "colab": {}
      },
      "source": [
        "model = Sequential()\n",
        "\n",
        "# This layer reduces the dimensions of the problem\n",
        "model.add(Embedding(max_features, 128))\n",
        "\n",
        "# This layer LSTM\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "\n",
        "# Output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam', \n",
        "              metrics=['accuracy'])\n",
        "# Summary\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 128)         2560000   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 128)               131584    \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 2,691,713\n",
            "Trainable params: 2,691,713\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hj6hrShPvabg",
        "colab_type": "code",
        "outputId": "3c1c8553-c1a7-4894-c99c-d722b7d67bff",
        "colab": {}
      },
      "source": [
        "unicorns = model.fit(x_train, y_train,\n",
        "          batch_size=1024, \n",
        "          epochs=2, \n",
        "          validation_data=(x_test,y_test))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 25000 samples, validate on 25000 samples\n",
            "Epoch 1/2\n",
            "25000/25000 [==============================] - 75s 3ms/sample - loss: 0.6261 - accuracy: 0.6772 - val_loss: 0.4940 - val_accuracy: 0.7995\n",
            "Epoch 2/2\n",
            "25000/25000 [==============================] - 82s 3ms/sample - loss: 0.3926 - accuracy: 0.8388 - val_loss: 0.3645 - val_accuracy: 0.8384\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T17q7WEhvabm",
        "colab_type": "code",
        "outputId": "70315c4a-6127-41fb-f656-3f2bb6af770e",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.plot(unicorns.history['loss'])\n",
        "plt.plot(unicorns.history['val_loss'])\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Test'], loc='upper left')\n",
        "plt.show();"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sa31fvMEvabr",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "You will be expected to use an Keras LSTM for a classicification task on the *Sprint Challenge*. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "7pETWPIe362y"
      },
      "source": [
        "# LSTM Text generation with Keras (Learn)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "G4ZVZSIuvabt"
      },
      "source": [
        "## Overview\n",
        "\n",
        "What else can we do with LSTMs? Since we're analyzing the *sequence*, we can do more than classify - we can *generate* text. I'ved pulled some news stories using [newspaper](https://github.com/codelucas/newspaper/).\n",
        "\n",
        "This example is drawn from the Keras [documentation](https://keras.io/examples/lstm_text_generation/)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqTevQPlT3wa",
        "colab_type": "text"
      },
      "source": [
        "# Method 1\n",
        "- Done by following lecture"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68rPrvtRvabv",
        "colab_type": "code",
        "outputId": "181430b9-35ac-49e3-8105-4a43398c4a67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 64
        }
      },
      "source": [
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "llQKK0vRxhqw",
        "colab_type": "code",
        "outputId": "7ae0bb34-dab0-4bf2-e1ca-733fb3c6e9e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# import files\n",
        "from zipfile import ZipFile\n",
        "\n",
        "file_name = \"/content/articles.zip\"\n",
        "\n",
        "with ZipFile(file_name, 'r') as zip:\n",
        "  zip.extractall()\n",
        "  print('Done')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pcfvo9f_vabz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_files = os.listdir('./articles')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jmOqvBjavab4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read in Data\n",
        "\n",
        "data = []\n",
        "\n",
        "for file in data_files:\n",
        "    if file[-3:] == 'txt':\n",
        "        with open(f'./articles/{file}', 'r', encoding='utf-8') as f:\n",
        "            data.append(f.read())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDyyaglfvab9",
        "colab_type": "code",
        "outputId": "ac3e325e-2704-4a8c-c544-b298a286209b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(data)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "136"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d80DPK6YvacD",
        "colab_type": "code",
        "outputId": "61acaddf-7826-41e9-df4f-560f73f2f86a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "data[-1]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'At the center of the bloody rampage unfolding in the “Church of Fake News” is a man dressed in a dark pinstripe suit. President Trump’s head is superimposed on his body.\\n\\nThe graphic images are from a fake video that was shown during a pro-Trump conference last week at the president’s hotel and golf resort near Miami, according to the New York Times, which first reported on the video’s existence Sunday night. The clip has since drawn intense backlash from journalists and public figures who have decried it as “vile and horrific” and an “incitement of violence.” Many of the news organizations and people featured in the video have been publicly targeted by Trump, who is frequently criticized for his inflammatory remarks and anti-media rhetoric.\\n\\nAD\\n\\nAD\\n\\n“This video isn’t funny,” tweeted former Texas congressman and Democratic presidential candidate Beto O’Rourke. “It will get people killed.”\\n\\nAt a conference of Trump supporters, they played a video of our president murdering journalists in a church. Last year, a Trump supporter sent bombs to CNN—and a shooter entered a church yesterday. This video isn’t funny. It will get people killed. https://t.co/XWtq1z38Kc — Beto O\\'Rourke (@BetoORourke) October 14, 2019\\n\\nOn Monday, White House press secretary Stephanie Grisham tweeted that Trump had not yet seen the clip, “but based upon everything he has heard, he strongly condemns this video.”\\n\\nRe: the video played over the weekend: The @POTUS @realDonaldTrump has not yet seen the video, he will see it shortly, but based upon everything he has heard, he strongly condemns this video. — Stephanie Grisham (@PressSec) October 14, 2019\\n\\nThe video, adapted from the scene of a church massacre in the 2014 film “Kingsman: The Secret Service,” appeared to be shared to YouTube in 2018 on a channel that posts similar pro-Trump content and has been linked to a meme-maker associated with a website called MemeWorld. The site’s creator, a user known by his Internet handle, Carpe Donktum, scored an Oval Office meeting in July with Trump, who reportedly welcomed him as a “genius.”\\n\\nAD\\n\\nCarpe Donktum confirmed in a Twitter message Sunday to The Washington Post that “The creator of the video is, and will remain a contributor to my site MemeWorld.” Carpe Donktum declined to identify the video’s creator citing concerns that the person may face online or in-person harassment.\\n\\nAD\\n\\nAlex Phillips, organizer of the American Priority Festival and Conference, told the Times the video was played at one point during the three-day event that began Thursday as part of a “meme exhibit.” The violent parody was included in a meme compilation that also featured Trump’s 2020 reelection campaign logo, according to the Times.\\n\\n“It has come to our attention that an unauthorized video was shown in a side room at #AMPFest19,” a statement posted to the conference’s website said. “This video was not approved, seen, or sanctioned by the #AMPFest19 organizers.”\\n\\nAD\\n\\nThe statement went on to note that the conference “always has and always will condemn political violence.”\\n\\nPhillips told the Times the “matter is under review.”\\n\\nIn a statement to The Post early Monday, the Trump campaign distanced itself from the video.\\n\\nAD\\n\\n“That video was not produced by the campaign, and we do not condone violence,” campaign spokesman Tim Murtaugh said.\\n\\nPeople close to Trump, such as former White House press secretary Sarah Sanders and Donald Trump Jr., were also scheduled to speak at the conference and told the Times they were not aware of the edited footage.\\n\\nThe video’s massacre scene opens with the Trump figure walking down the center aisle of a packed church. More than a dozen of the parishioners’ faces are covered by the logos of major media organizations, ranging from PBS to The Washington Post. Rising out of the pews when Trump passes them, some of the churchgoers appear to be yelling at the president, whose face contorts into a scowl.\\n\\nAD\\n\\nAs the shouting intensifies, Trump abruptly stops walking and turns to face the angry mob. He pulls out a black gun from his jacket’s inside pocket and shoots a person edited to represent late actor Peter Fonda, who was a vocal critic of the president, in the head from point-blank range.\\n\\nAD\\n\\nThen, chaos ensues.\\n\\nTrump takes down Bloomberg, Vox and “Fake News” in quick succession before shooting Politico. At one point, he grabs someone who represents the Black Lives Matter movement in a chokehold and shoots that person in the head.\\n\\nAfter shooting MSNBC host Rachel Maddow, Vice News, Rep. Adam B. Schiff (D-Calif.) and Slate, Trump tries to shoot late senator John McCain (R-Ariz.), but he is out of bullets. Instead, he uses his gun to deliver a vicious blow to the back of McCain’s neck.\\n\\nAD\\n\\nThe attack continues with Trump going after some of his most prominent detractors. He stabs actress and comedian Rosie O’Donnell and repeatedly punches Rep. Maxine Waters (D-Calif.). He goes on to shoot MSNBC’s Mika Brzezinski and Sen. Mitt Romney (R-Utah), and later assaults Hillary Clinton with a gun.\\n\\nAD\\n\\nThe video comes to a dramatic end when Trump jams a sharp wooden stake through the head of a person whose face is a CNN logo. A now-grinning Trump appears to survey the carnage as DJ Khaled’s song, “All I Do Is Win,” plays in the background. A pair of pixelated black sunglasses are lowered onto Trump’s face.\\n\\nBy late Sunday, “Kingsman” was trending on Twitter with many expressing outrage at the video and calling on Trump to condemn it.\\n\\nAD\\n\\n“Sadly, this is not the first time that supporters of the President have promoted violence against the media in a video they apparently find entertaining — but it is by far and away the worst,” CNN said in a statement shared on Twitter.\\n\\nThe images in the recent video are “vile and horrific,” CNN said, adding, “The President and his family, the White House, and the Trump campaign need to denounce it immediately in the strongest possible terms. Anything less equates to a tacit endorsement of violence and should not be tolerated by anyone.”\\n\\nAD\\n\\nWhite House Correspondents’ Association President Jonathan Karl of ABC News also denounced the video, noting that Trump has been warned that “his rhetoric could incite violence.”\\n\\nAD\\n\\nWHCA Statement on video depicting President Trump murdering journalists. pic.twitter.com/52lHFaQjU2 — WHCA (@whca) October 14, 2019\\n\\nKarl’s statement was supported early Monday by Cindy McCain, who tweeted that the images in the video of the president killing the media and her late husband “violate every norm our society expects from its leaders.”\\n\\nTrump has made it a habit to publicly lambaste the media, individual journalists and his critics, leading to heightened concerns about safety. In 2017, the president was widely criticized for tweeting a similarly edited video that showed him body slamming a person with a CNN logo for a face during a pro wrestling match. Earlier this year, Cesar Sayoc, a devoted Trump supporter, was sentenced to 20 years in prison for mailing 13 pipe bombs to high-profile Democrats, several of whom were featured in the recent video, and CNN.\\n\\nAD\\n\\nOn Sunday, journalists and political commentators suggested the church video is further evidence that Trump’s words have influenced his supporters.\\n\\nAD\\n\\n“This is an incitement to violence that didn’t just come from the dark corners of the Internet — it was shown at a pro-Trump conference at one of his resorts,” tweeted Politico reporter Andrew Desiderio. “I’m speechless.”\\n\\nCNN commentator Ana Navarro-Cárdenas wrote, “Trump has legitimized hate.”\\n\\nEnablers choose to deny it, but this is the kind of crap Trump peddles & inspires. His constant attacks on the free press, the chants against journalists at his rallies, his retweeting of similar memes...Trump has legitimized hate. #Deplorable https://t.co/vqk0w9Kd9n — Ana Navarro-Cárdenas (@ananavarro) October 14, 2019\\n\\nA year ago this month a man mailed bombs to journalists, Democratic leaders, and critics of Donald Trump. He was responding to Trump’s violent rhetoric. Now we’ve got videos of mass slaughters.\\n\\n\\n\\nThere’s literally no telling what kind of dangers they could unleash. — Jared Yates Sexton (@JYSexton) October 14, 2019\\n\\nCall someone an \"enemy\" over and over again, and you have some responsibility for what happens to them.\\n\\n\\n\\nTrump is responsible for a climate that is so hateful, so hostile toward journalists that it spawns videos like this one. https://t.co/mn1W8W69M1 — Brian Stelter (@brianstelter) October 14, 2019\\n\\nActress Kathy Griffin, who drew widespread backlash in 2017 after sharing a photo of herself holding a prop of Trump’s bloody severed head, echoed concerns about the clip’s impact. Griffin, shown in the video getting beheaded by the ax-wielding CNN person, tweeted that it “isn’t a joke” to Trump supporters, adding, “And it will not be taken as such.\"\\n\\nBut some pushed back against criticisms of the video, pointing out that the film’s original scene, which depicted a church full of “conservative Christians” being killed, did not draw the same level of outcry. According to an NPR review of the movie, the fictional congregation was “clearly modeled on the Westboro Baptist Church,” a Kansas-based organization known for its anti-gay views.\\n\\nAD\\n\\nStill, others wondered if the video represents, as one person put it, “the country hitting rock bottom.”\\n\\n“We have enough mass shootings, we have enough journalists killed in the line of duty around the world — we don’t need to glorify a massacre of people who challenge Trump,” Times columnist Nicholas Kristof tweeted. “This demonization of opponents and fetishization of violence is unconscionable.”'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iwC_YPe1vacK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Encode Data as Chars\n",
        "\n",
        "# Gather all text \n",
        "# Why? 1. See all possible characters 2. For training / splitting later\n",
        "text = \" \".join(data)\n",
        "\n",
        "# Unique Characters\n",
        "chars = list(set(text))\n",
        "\n",
        "# Lookup Tables\n",
        "char_int = {c:i for i, c in enumerate(chars)} \n",
        "int_char = {i:c for i, c in enumerate(chars)} "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PG1JQJ2zvacP",
        "colab_type": "code",
        "outputId": "2b8b1ec4-b6b8-49e4-88b5-41a123cc1af7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(chars)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "121"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rF3iZTzbvacT",
        "colab_type": "code",
        "outputId": "a726c193-5fec-4eea-aeef-7ad68cd97ed2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Create the sequence data\n",
        "\n",
        "maxlen = 40\n",
        "step = 5\n",
        "\n",
        "encoded = [char_int[c] for c in text]\n",
        "\n",
        "sequences = [] # Each element is 40 chars long\n",
        "next_char = [] # One element for each sequence\n",
        "\n",
        "for i in range(0, len(encoded) - maxlen, step):\n",
        "    \n",
        "    sequences.append(encoded[i : i + maxlen])\n",
        "    next_char.append(encoded[i + maxlen])\n",
        "    \n",
        "print('sequences: ', len(sequences))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sequences:  178374\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SWuUfQt6vacY",
        "colab_type": "code",
        "outputId": "98d74d57-b95c-48f9-fab7-942faf8816fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 710
        }
      },
      "source": [
        "sequences[0]"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[5,\n",
              " 40,\n",
              " 22,\n",
              " 96,\n",
              " 61,\n",
              " 22,\n",
              " 55,\n",
              " 6,\n",
              " 61,\n",
              " 17,\n",
              " 6,\n",
              " 40,\n",
              " 43,\n",
              " 17,\n",
              " 6,\n",
              " 49,\n",
              " 92,\n",
              " 90,\n",
              " 105,\n",
              " 6,\n",
              " 80,\n",
              " 61,\n",
              " 92,\n",
              " 12,\n",
              " 90,\n",
              " 43,\n",
              " 61,\n",
              " 40,\n",
              " 6,\n",
              " 55,\n",
              " 92,\n",
              " 77,\n",
              " 33,\n",
              " 61,\n",
              " 17,\n",
              " 40,\n",
              " 22,\n",
              " 17,\n",
              " 6,\n",
              " 40]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juTJgh-avacc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Create x & y\n",
        "\n",
        "x = np.zeros((len(sequences), maxlen, len(chars)), dtype=np.bool)\n",
        "y = np.zeros((len(sequences),len(chars)), dtype=np.bool)\n",
        "\n",
        "for i, sequence in enumerate(sequences):\n",
        "    for t, char in enumerate(sequence):\n",
        "        x[i,t,char] = 1\n",
        "        \n",
        "    y[i, next_char[i]] = 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gCXAsBa_vacg",
        "colab_type": "code",
        "outputId": "32e019ac-b68a-4812-f7f5-c66fcbd9cec3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(178374, 40, 121)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tGT0qat9vack",
        "colab_type": "code",
        "outputId": "e41ba183-4922-4d9c-84f0-5919967b8416",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(178374, 121)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lmfubjjxvacq",
        "colab_type": "code",
        "outputId": "8c019533-fd10-4216-9f96-049da3ced286",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        }
      },
      "source": [
        "# build the model: a single LSTM\n",
        "\n",
        "model = Sequential()\n",
        "model.add(LSTM(128, input_shape=(maxlen, len(chars)), dropout=.2))\n",
        "model.add(Dense(len(chars), activation='softmax'))\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "lstm_1 (LSTM)                (None, 128)               128000    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 121)               15609     \n",
            "=================================================================\n",
            "Total params: 143,609\n",
            "Trainable params: 143,609\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xv5eToRQvacu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sample(preds):\n",
        "    # helper function to sample an index from a probability array\n",
        "    # Takes predictions and translates them into a character.\n",
        "    # Into a position of a chracter.\n",
        "    preds = np.asarray(preds).astype('float64')\n",
        "    preds = np.log(preds) / 1\n",
        "    exp_preds = np.exp(preds)\n",
        "    preds = exp_preds / np.sum(exp_preds)\n",
        "    probas = np.random.multinomial(1, preds, 1)\n",
        "    return np.argmax(probas)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uem1umOmvacy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def on_epoch_end(epoch, _):\n",
        "    # Function invoked at end of each epoch. Prints generated text.\n",
        "    \n",
        "    print()\n",
        "    print('----- Generating text after Epoch: %d' % epoch)\n",
        "    \n",
        "    start_index = random.randint(0, len(text) - maxlen - 1)\n",
        "    \n",
        "    generated = ''\n",
        "    \n",
        "    sentence = text[start_index: start_index + maxlen]\n",
        "    generated += sentence\n",
        "    \n",
        "    print('----- Generating with seed: \"' + sentence + '\"')\n",
        "    sys.stdout.write(generated)\n",
        "    \n",
        "    for i in range(400):\n",
        "        x_pred = np.zeros((1, maxlen, len(chars)))\n",
        "        for t, char in enumerate(sentence):\n",
        "            x_pred[0, t, char_int[char]] = 1\n",
        "            \n",
        "        preds = model.predict(x_pred, verbose=0)[0]\n",
        "        next_index = sample(preds)\n",
        "        next_char = int_char[next_index]\n",
        "        \n",
        "        sentence = sentence[1:] + next_char\n",
        "        \n",
        "        sys.stdout.write(next_char)\n",
        "        sys.stdout.flush()\n",
        "    print()\n",
        "\n",
        "\n",
        "print_callback = LambdaCallback(on_epoch_end=on_epoch_end)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpmfUvjJvac2",
        "colab_type": "code",
        "outputId": "dbf7c369-e35b-4808-b28f-c1c8d688a9e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# fit the model\n",
        "\n",
        "model.fit(x, y,\n",
        "          batch_size=1024,\n",
        "          epochs=10,\n",
        "          callbacks=[print_callback])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 178374 samples\n",
            "Epoch 1/10\n",
            "178176/178374 [============================>.] - ETA: 0s - loss: 3.2845\n",
            "----- Generating text after Epoch: 0\n",
            "----- Generating with seed: \"Best Dressed Fan award goes to the guy i\"\n",
            "Best Dressed Fan award goes to the guy ihc hateduf a    e aVrnni .O hitores iueugttnAosse\n",
            "o e.iimEtm t\n",
            "idoy  urhahiy eye .psfit so odigeot p e eCrroe  arr Rgridosn”sttleormiabsye, n e ud d mlbtnouaTbsh  webed e tm iT bbyfI brvsi e. s uh n tr.stdoion ur“ys  ur tH wngnhv  /eht dvyfrt c,0SsnenY aReet  ppeenl  mnlitfowoeeguylh.yhAn,eeoo “hb  afa sofnyatemcxtngatm iefrteur e neag am oi”1ptt h  tlnnn eap  nor oofgssral5ma  d’Cathttt  öado -ig\n",
            "178374/178374 [==============================] - 21s 120us/sample - loss: 3.2843\n",
            "Epoch 2/10\n",
            "178176/178374 [============================>.] - ETA: 0s - loss: 3.0087\n",
            "----- Generating text after Epoch: 1\n",
            "----- Generating with seed: \"e politics of the right and inspiring in\"\n",
            "e politics of the right and inspiring ina in e penoyo.a rsookbero oohe pv hpn evs  rer his afe inot icsq rel eur oirove c sil itsh. arcAy saitamao6eslgsamte. ralomhdsyA ahp laris eepe oAbe uuay\n",
            "  womiomtnm lane ryo od afeaaex ws iur uinsie .cafoul nes asrrAgmoJ  lhlllchPee welleine oet Pot)eraoTne Hi ei.fea rr 5ecyasa tno s .iRs“Ife f\n",
            " enlSf nooad ,oed aiasi2se,rDhiE leroticlomlorai5 ls t Ano pusf sprluwS oc togecot,iCs n asa AhnSiatalc\n",
            "178374/178374 [==============================] - 20s 113us/sample - loss: 3.0086\n",
            "Epoch 3/10\n",
            "178176/178374 [============================>.] - ETA: 0s - loss: 2.7879\n",
            "----- Generating text after Epoch: 2\n",
            "----- Generating with seed: \"e they suspect of having committed immig\"\n",
            "e they suspect of having committed immig ih, by ve tho’ntt wath, orSsar pr“to Condeb6aned ha,pSfuRpo chin inbetn” bwenr s’r o ar int woe af-thd chise af be fiwtfhe,ilP“yat jal okrGegd ome:iss rasgtunlb\n",
            "\n",
            "“mor henmh, \n",
            "\n",
            "”epornum2 imge oa pansihe” Anrept\n",
            "ir s\n",
            "asat lesd rPoas bysarRorlmnosat nr serdfris il th cucl cavyy tu ta, re,esadf Bt Careghe Ffreonth, ceras ra naded b’cile edvaltess anr, FJeh, Q3ityes oaw toa 7eis sid en thicgas rbstiga\n",
            "178374/178374 [==============================] - 20s 110us/sample - loss: 2.7880\n",
            "Epoch 4/10\n",
            "178176/178374 [============================>.] - ETA: 0s - loss: 2.6645\n",
            "----- Generating text after Epoch: 3\n",
            "----- Generating with seed: \"front leg is opened up a bit more this s\"\n",
            "front leg is opened up a bit more this sout rrpeliald dh thuSwaas, — bu alal  n Il se0 wao nopbay) 2ho,ed ov unscada ssofacf bivu e, Ont Ar, Touedir themey osgards ’or we ritet so]l sanstbon pad sa-bviFciedtyoma senmlsy us herphicici bullins axouo car, waag ore oob the ahetr tho soucessios uire ferts ainsert ouyon \n",
            "\n",
            "he fozmeceeDaut palatborath kenr ars, di’Hon  on tiwnide —hDhe. oen arpalhin ont wimeveia furn. onac\n",
            "\n",
            "ms an bsy Sute ., ID\n",
            "178374/178374 [==============================] - 19s 109us/sample - loss: 2.6644\n",
            "Epoch 5/10\n",
            "178176/178374 [============================>.] - ETA: 0s - loss: 2.5895\n",
            "----- Generating text after Epoch: 4\n",
            "----- Generating with seed: \"ch soil because of the escape of some Is\"\n",
            "ch soil because of the escape of some Isbader. Cherita ingaud .en ate seloun tis wares ufnon ere ifere $itry CoTr bebson ?os  oreccoomgo, wra te on eaget hon wos onesinh Ase vels kiv erunnghes.\n",
            "\n",
            "Iod zuliitorn yay:.\n",
            "\n",
            "Phe ‘erI rise t gofchafkinitl ufpelamprsmd.bee as abther co— th ves ooce foalt, we’s loceince birg theonvian’y 1oac Saumongs anipae wat’ sie the tow, bias corion sape riyes sady.\n",
            "\n",
            "dirta Aro doupee on ehe coddine6tho pid alee\n",
            "178374/178374 [==============================] - 19s 109us/sample - loss: 2.5895\n",
            "Epoch 6/10\n",
            "178176/178374 [============================>.] - ETA: 0s - loss: 2.5388\n",
            "----- Generating text after Epoch: 5\n",
            "----- Generating with seed: \"t yet seen the clip, “but based upon eve\"\n",
            "t yet seen the clip, “but based upon eved’ge bauhstoncintepin wid they Theloncome  at eedionk see that the phadbetit 8terp Inpl Plabdiag “lins bheyo pou. the Fur ma thisteca eruted, on maun, vaming yificiake, kad “thscoL teust in to ta moumxMvenelthis mvesy trke g cor thert1y ro  dlar ancin encat in bpsat’ daw ddats nthe astiof weren mace porliane Tstip  amemp sos bend dritint I: fo. Irir lot or setmlcarise toonut6 Tong jung burg pfeel \n",
            "178374/178374 [==============================] - 20s 110us/sample - loss: 2.5388\n",
            "Epoch 7/10\n",
            "178176/178374 [============================>.] - ETA: 0s - loss: 2.4983\n",
            "----- Generating text after Epoch: 6\n",
            "----- Generating with seed: \"d things get,” he insisted, “you can sti\"\n",
            "d things get,” he insisted, “you can stial hes. S9amof Kincopnenty Tupladise hTre s 1hab““N UtT He Hempsebed in Wouns an yo 1He sut the on weam ouproup ol. come teend poone tous” but 1y srinqfay thut thorche prerrire, viuudengive cos 2 meact aom’sh Mertidt ,nd dsirde tay wacmogher sistrerte sh spunongs. “mim couGtac salyos acastiliug Wes Ment ser.\n",
            "\n",
            "Diecteve ersialcighen Onldtsovesaly, ans, U 1hisshe oouts roly.\n",
            "et sfleth the Arpersasish\n",
            "178374/178374 [==============================] - 19s 109us/sample - loss: 2.4982\n",
            "Epoch 8/10\n",
            "178176/178374 [============================>.] - ETA: 0s - loss: 2.4637\n",
            "----- Generating text after Epoch: 7\n",
            "----- Generating with seed: \"es in Congress's impeachment inquiry as \"\n",
            "es in Congress's impeachment inquiry as 3ics oul ad or Saunges uan. The 4yEerunchi, Tourby and irs challe cise seg and yet hos licct to atiig zadefthe ming’s, bitha deot rugsimetrsathe Russ alleen shes rond thea hes l mat$ mamin, pipraticed os ceippads stomeat on seanstas whs herct,ed and os mevery pessimitiin, heit the Mltiding tho saly.\n",
            "\n",
            "Fmen, one.\n",
            "\n",
            "Ocls vo onkjubliss.\n",
            "\n",
            "In to melled ledibel lryibl frehtcellt.\n",
            "\n",
            "A. Tritcus fove 2r’n ans\n",
            "178374/178374 [==============================] - 19s 108us/sample - loss: 2.4637\n",
            "Epoch 9/10\n",
            "178176/178374 [============================>.] - ETA: 0s - loss: 2.4354\n",
            "----- Generating text after Epoch: 8\n",
            "----- Generating with seed: \"ion and commercial work before making hi\"\n",
            "ion and commercial work before making hit or ounid un woop rep vack sond an’r Kompucotinat..\n",
            "\n",
            "Ther beseve fordvert ser whitcapre it 1ep Ter1 Dlow thif cipprisowver ithecthon hor of bed (hh 20“3hy Cxiskis surtent mo so. Potrp‘ad wingeld jonste the tomewe rhwo the Wckemas, an Erithat be Scobecc pevaipe tore ion.\n",
            "\n",
            "U.\n",
            "\n",
            "Seok onf the thiden, h cali trome couk-boture than’s weaskern hom sitr, ig on cork and khwar, asdedinctoY\n",
            "PPa3h socinnt cem\n",
            "178374/178374 [==============================] - 19s 109us/sample - loss: 2.4355\n",
            "Epoch 10/10\n",
            "178176/178374 [============================>.] - ETA: 0s - loss: 2.4080\n",
            "----- Generating text after Epoch: 9\n",
            "----- Generating with seed: \"We noticed you’re blocking ads!\n",
            "\n",
            "Keep su\"\n",
            "We noticed you’re blocking ads!\n",
            "\n",
            "Keep suuptol,, Peepdoy cortingy andd of inm hatyes longring aby fat onebowihg waLhen seiden teat. Imp sther tioning frive soutinn gok.\n",
            "\n",
            "Fweve hath as, cass. Trkn ivt wect andFor tard picess-yoregn\n",
            "\n",
            "Eca the lowlrenon mente, Ficuved al tems peonlieg,’s eoute ront the bycthal oul ia maty Plaso.\n",
            "\n",
            "The whay of thechigh courn Bof rnailesporats his le diwe houcs and went the boursting of os pefvint is’w Wher bou\n",
            "178374/178374 [==============================] - 19s 108us/sample - loss: 2.4083\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f34b00955c0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8hyqHH5DTxSR",
        "colab_type": "text"
      },
      "source": [
        "# Method 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIhvHLpeUBkR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "outputId": "468d351d-ea6e-40bf-c9ce-ba98981cbc1b"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "import sys\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.callbacks import LambdaCallback\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, LSTM\n",
        "from tensorflow.keras.optimizers import RMSprop"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<p style=\"color: red;\">\n",
              "The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n",
              "We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n",
              "or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n",
              "<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2KR-OUIAvac8",
        "colab_type": "text"
      },
      "source": [
        "## Challenge\n",
        "\n",
        "You will be expected to use a Keras LSTM to generate text on today's assignment. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HN6Mcx8Hvac9",
        "colab_type": "text"
      },
      "source": [
        "# Review\n",
        "\n",
        "- <a href=\"#p1\">Part 1: </a>Describe Neural Networks used for modeling sequences\n",
        "    * Sequence Problems:\n",
        "        - Time Series (like Stock Prices, Weather, etc.)\n",
        "        - Text Classification\n",
        "        - Text Generation\n",
        "        - And many more! :D\n",
        "    * LSTMs are generally preferred over RNNs for most problems\n",
        "    * LSTMs are typically a single hidden layer of LSTM type; although, other architectures are possible.\n",
        "    * Keras has LSTMs/RNN layer types implemented nicely\n",
        "- <a href=\"#p2\">Part 2: </a>Apply a LSTM to a text generation problem using Keras\n",
        "    * Shape of input data is very important\n",
        "    * Can take a while to train\n",
        "    * You can use it to write movie scripts. :P "
      ]
    }
  ]
}